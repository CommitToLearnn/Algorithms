<div align="center">

<img width="100%" src="https://capsule-render.vercel.app/api?type=waving&color=3776AB&height=200&section=header&text=KNN%20Python&fontSize=50&fontColor=fff&animation=twinkling&fontAlignY=40&desc=K-Nearest%20Neighbors%20Algorithm%20in%20Python&descAlignY=60&descSize=18">

<p align="center">
  <i>üêç Simple yet powerful K-Nearest Neighbors implementation in Python with NumPy optimization</i>
</p>

---

</div>

# K-Nearest Neighbors (KNN) - Python üêç

## üìù Descri√ß√£o

O algoritmo K-Nearest Neighbors (KNN) √© um dos algoritmos de aprendizado de m√°quina mais simples e intuitivos. √â um algoritmo de classifica√ß√£o **lazy** (pregui√ßoso) que classifica um ponto baseado na classe majorit√°ria dos K vizinhos mais pr√≥ximos.

## üßÆ Complexidade

| Opera√ß√£o | Vers√£o B√°sica | Vers√£o Otimizada |
|----------|---------------|------------------|
| **Treinamento** | O(1) | O(1) |
| **Predi√ß√£o** | O(n¬∑d) | O(n¬∑d) / O(log n) com KD-Tree |
| **Espa√ßo** | O(n¬∑d) | O(n¬∑d) |

Onde:
- `n` = n√∫mero de pontos de treino
- `d` = dimensionalidade dos dados

## üéØ Quando Usar

### ‚úÖ Ideal para:
- Datasets pequenos a m√©dios (< 10.000 exemplos)
- Dados com baixa dimensionalidade (< 20 caracter√≠sticas)
- Problemas onde a estrutura local dos dados √© importante
- Baseline para compara√ß√£o com outros algoritmos
- Sistemas de recomenda√ß√£o simples

### ‚ùå Evitar quando:
- Datasets muito grandes (> 100.000 exemplos)
- Alta dimensionalidade (curse of dimensionality)
- Dados com muito ru√≠do
- Caracter√≠sticas com escalas muito diferentes (sem normaliza√ß√£o)

## üìÅ Estrutura dos Arquivos

```
python/knn/
‚îú‚îÄ‚îÄ knn_basico.py      # üéØ Implementa√ß√£o did√°tica
‚îú‚îÄ‚îÄ otimizado/
‚îÇ   ‚îî‚îÄ‚îÄ knn_otimizado.py   # üöÄ Vers√£o otimizada
‚îî‚îÄ‚îÄ README.md          # üìñ Esta documenta√ß√£o
```

## üöÄ Como Executar

### Vers√£o B√°sica
```bash
cd python/knn
python knn_basico.py
```

### Vers√£o Otimizada
```bash
cd python/knn/otimizado
pip install numpy  # Instala depend√™ncia
python knn_otimizado.py
```

## üéì Conceitos Fundamentais

### 1. **Algoritmo Lazy**
O KNN n√£o constr√≥i um modelo expl√≠cito durante o treinamento. Simplesmente armazena todos os dados de treino e faz computa√ß√µes durante a predi√ß√£o.

### 2. **Escolha do K**
- **K muito pequeno**: Sens√≠vel a ru√≠do, overfitting
- **K muito grande**: Perda de informa√ß√£o local, underfitting
- **Regra pr√°tica**: K = ‚àön ou usar valida√ß√£o cruzada

### 3. **M√©tricas de Dist√¢ncia**

#### Dist√¢ncia Euclidiana (L2)
```
d(x,y) = ‚àö(Œ£(xi - yi)¬≤)
```
- Mais comum
- Sens√≠vel a outliers
- Assume import√¢ncia igual para todas as dimens√µes

#### Dist√¢ncia Manhattan (L1)
```
d(x,y) = Œ£|xi - yi|
```
- Menos sens√≠vel a outliers
- √ötil para dados categ√≥ricos ordinais

#### Dist√¢ncia Minkowski (Lp)
```
d(x,y) = (Œ£|xi - yi|^p)^(1/p)
```
- Generaliza√ß√£o das anteriores
- p=1: Manhattan, p=2: Euclidiana

#### Dist√¢ncia Cosseno
```
d(x,y) = 1 - (x¬∑y)/(||x||¬∑||y||)
```
- Mede √¢ngulo entre vetores
- √ötil para dados de alta dimens√£o
- Ignora magnitude, foca na dire√ß√£o

## üí° Implementa√ß√µes

### üéØ Vers√£o B√°sica (`knn_basico.py`)

**Foco**: Clareza e entendimento dos conceitos

**Caracter√≠sticas**:
- Implementa√ß√£o step-by-step com coment√°rios extensos
- Visualiza√ß√£o detalhada do processo de classifica√ß√£o
- C√°lculo manual de dist√¢ncias
- Demonstra√ß√£o com datasets simples

**Exemplo de uso**:
```python
from knn_basico import KNNBasico

# Dados de exemplo: [caracter√≠stica1, caracter√≠stica2] -> classe
dados = [
    ([2.0, 1.0], "A"),
    ([5.0, 3.0], "B"),
    ([6.5, 4.0], "C")
]

# Inicializa classificador
knn = KNNBasico(k=3)

# Treina (apenas armazena dados)
knn.treinar(dados)

# Classifica novo ponto
resultado = knn.classificar([3.0, 2.0])
print(f"Classe prevista: {resultado}")
```

### üöÄ Vers√£o Otimizada (`knn_otimizado.py`)

**Foco**: Performance e recursos avan√ßados

**Caracter√≠sticas**:
- Opera√ß√µes vetorizadas com NumPy
- M√∫ltiplas m√©tricas de dist√¢ncia
- Normaliza√ß√£o autom√°tica de dados
- Valida√ß√£o cruzada para sele√ß√£o de hiperpar√¢metros
- An√°lise detalhada de performance
- Estruturas de dados otimizadas

**Depend√™ncias**:
```bash
pip install numpy
```

**Exemplo de uso**:
```python
from knn_otimizado import KNNOtimizado, MetricaDistancia
import numpy as np

# Dados sint√©ticos
X = np.random.randn(1000, 4)  # 1000 exemplos, 4 caracter√≠sticas
y = np.random.choice(['A', 'B', 'C'], 1000)

# Divide treino/teste
X_treino, X_teste = X[:800], X[800:]
y_treino, y_teste = y[:800], y[800:]

# Cria modelo otimizado
knn = KNNOtimizado(
    k=5,
    metrica=MetricaDistancia.EUCLIDIANA,
    normalizar=True
)

# Treina
knn.treinar(X_treino, y_treino)

# Prediz
predicoes = knn.predizer(X_teste)

# Avalia performance
stats = knn.avaliar_performance(X_teste, y_teste)
print(f"Acur√°cia: {stats.acuracia:.3f}")
```

## üìä Compara√ß√£o de Performance

| Aspecto | B√°sica | Otimizada |
|---------|--------|-----------|
| **Velocidade** | ~1000 ms | ~10 ms |
| **Mem√≥ria** | Listas Python | Arrays NumPy |
| **M√©tricas** | Euclidiana | 4 m√©tricas |
| **Normaliza√ß√£o** | Manual | Autom√°tica |
| **Valida√ß√£o** | N√£o | Cross-validation |
| **An√°lise** | B√°sica | Completa |

## üõ†Ô∏è T√©cnicas de Otimiza√ß√£o

### 1. **Normaliza√ß√£o de Dados**
```python
# Z-score normalization
X_norm = (X - X.mean()) / X.std()
```
- Essencial quando caracter√≠sticas t√™m escalas diferentes
- Evita domin√¢ncia de caracter√≠sticas com valores grandes

### 2. **Sele√ß√£o de K por Valida√ß√£o Cruzada**
```python
# Testa diferentes valores de k
melhor_k = knn.validacao_cruzada(X, y, k_range=range(1, 21))
```

### 3. **Otimiza√ß√µes Algor√≠tmicas**
- **KD-Tree**: Para busca eficiente em baixa dimens√£o
- **LSH**: Locality Sensitive Hashing para alta dimens√£o
- **Ball Tree**: Para m√©tricas de dist√¢ncia arbitr√°rias

## üß™ Exerc√≠cios Pr√°ticos

### Iniciante
1. **Teste diferentes valores de K** em um dataset e observe o efeito na acur√°cia
2. **Compare m√©tricas de dist√¢ncia** no mesmo dataset
3. **Implemente visualiza√ß√£o 2D** dos resultados de classifica√ß√£o

### Intermedi√°rio
4. **Adicione pesos baseados na dist√¢ncia** (vizinhos mais pr√≥ximos t√™m maior peso)
5. **Implemente KNN para regress√£o** (prever valores cont√≠nuos)
6. **Crie detector de outliers** baseado na dist√¢ncia m√©dia aos vizinhos

### Avan√ßado
7. **Implemente KD-Tree** para busca eficiente
8. **Adicione feature selection** autom√°tica
9. **Crie KNN incremental** para dados em streaming

## üìö Casos de Uso Reais

### 1. **Sistema de Recomenda√ß√£o**
```python
# Recomenda produtos baseado em usu√°rios similares
usuarios_similares = knn.encontrar_k_vizinhos(perfil_usuario)
produtos_recomendados = recomendar_baseado_em_vizinhos(usuarios_similares)
```

### 2. **Classifica√ß√£o de Imagens**
```python
# Classifica imagem baseada em caracter√≠sticas extra√≠das
caracteristicas_imagem = extrair_caracteristicas(imagem)
classe_imagem = knn.classificar(caracteristicas_imagem)
```

### 3. **Diagn√≥stico M√©dico**
```python
# Classifica paciente baseado em sintomas
sintomas_paciente = [febre, dor_cabeca, nausea, ...]
diagnostico = knn.classificar(sintomas_paciente)
```

## ‚ö° Dicas de Performance

1. **Use normaliza√ß√£o** quando caracter√≠sticas t√™m escalas diferentes
2. **Reduza dimensionalidade** com PCA para dados de alta dimens√£o
3. **Use m√©tricas adequadas**: Manhattan para dados categ√≥ricos, Euclidiana para cont√≠nuos
4. **Considere sampling** para datasets muito grandes
5. **Implemente early stopping** na busca de vizinhos quando poss√≠vel

## üîó Recursos Adicionais

- [Scikit-learn KNN Documentation](https://scikit-learn.org/stable/modules/neighbors.html)
- [Curse of Dimensionality in KNN](https://en.wikipedia.org/wiki/Curse_of_dimensionality)
- [KD-Tree Data Structure](https://en.wikipedia.org/wiki/K-d_tree)
- [Cross-validation Techniques](https://scikit-learn.org/stable/modules/cross_validation.html)

### üë§ Author | Autor

<div align="center">
  <a href="https://github.com/matheussricardoo" target="_blank">
    <img src="https://skillicons.dev/icons?i=github" alt="GitHub"/>
  </a>
  <a href="https://www.linkedin.com/in/matheus-ricardo-426452266/" target="_blank">
    <img src="https://skillicons.dev/icons?i=linkedin" alt="LinkedIn"/>
  </a>
</div>

### üìÑ License | Licen√ßa

This project is licensed under the MIT License. See the [LICENSE](../../LICENSE) file for details.

Este projeto est√° licenciado sob a Licen√ßa MIT. Veja o arquivo [LICENSE](../../LICENSE) para mais detalhes.

### üôè Acknowledgments | Agradecimentos

- **NumPy Community** for providing excellent mathematical operations
- **Scikit-learn** team for inspiring best practices in ML algorithms
- **Python Community** for making machine learning accessible to everyone
- All contributors who helped improve this implementation

---

<div align="center">
  <i>üí° Python makes machine learning simple and intuitive!</i>
  <br>
  <i>üí° Python torna o machine learning simples e intuitivo!</i>
</div>

<img width="100%" src="https://capsule-render.vercel.app/api?type=waving&color=3776AB&height=120&section=footer"/>

</div>
